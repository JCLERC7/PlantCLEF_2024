{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import timm.utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Function to set the seed for reproducibility\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    # The below two lines are for deterministic algorithm behavior in CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/training/dataset\"\n",
    "nbr_classes = len(os.listdir(data_dir))\n",
    "nbr_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_mapping(class_list_file):\n",
    "    with open(class_list_file) as f:\n",
    "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
    "    return class_index_to_class_name\n",
    "\n",
    "\n",
    "def load_species_mapping(species_map_file):\n",
    "    df = pd.read_csv(species_map_file, sep=';', quoting=1, dtype={'species_id': str})\n",
    "    df = df.set_index('species_id')\n",
    "    return  df['species'].to_dict()\n",
    "\n",
    "cid_to_spid = load_class_mapping(\"models/pretrained_models/class_mapping.txt\")\n",
    "spid_to_sp = load_species_mapping(\"models/pretrained_models/species_id_to_name.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 518x518\n",
    "    transforms.Resize(size=(518,518)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # p = probability of flip, 0.5 = 50% chance\n",
    "    # Add your custom augmentation here\n",
    "    transforms.RandomApply([transforms.TrivialAugmentWide(num_magnitude_bins=31)], p=0.5),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize the image\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def one_hot(label_idx, nbr_classes):\n",
    "    one_hot_tensor = torch.zeros(nbr_classes)\n",
    "    one_hot_tensor.scatter_(0, torch.tensor(label_idx), value=1)\n",
    "    return one_hot_tensor\n",
    "\n",
    "label_transformation = transforms.Compose([transforms.Lambda(lambda y: one_hot(y, nbr_classes))])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir,\n",
    "                            transform=data_transform,\n",
    "                            target_transform= label_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor:\n",
      "tensor([[[-0.5596, -0.8164, -0.4397,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-0.5424, -0.4568, -0.3712,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-0.5938, -0.4911, -0.5596,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-1.2788, -1.3815, -1.5185,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-1.3644, -1.3473, -1.4329,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-1.4672, -1.4158, -1.4329,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[ 0.5028,  0.1352,  0.4853,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [ 0.6254,  0.6429,  0.7129,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [ 0.7129,  0.7654,  0.6779,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-0.3725, -0.5476, -0.6877,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-0.6352, -0.6527, -0.7402,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-0.8627, -0.7752, -0.8102,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-0.4275, -0.6715, -0.2881,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-0.3578, -0.2707, -0.1835,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-0.4101, -0.2881, -0.3578,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.2293, -1.3164, -1.4559,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.1247, -1.1421, -1.2293,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.0898, -1.1073, -1.1247,  ..., -1.8044, -1.8044, -1.8044]]])\n",
      "Image shape: torch.Size([3, 518, 518])\n",
      "Image datatype: torch.float32\n",
      "Image label: tensor([1., 0., 0.,  ..., 0., 0., 0.])\n",
      "Label datatype: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0][0], dataset[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer( experiment_name: str, model_name: str, extra: str=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "    \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs\\2024-05-26\\Run_3\\vit_small_patch14_reg4_dinov2\\lr-8.0e-05_epoch-100_batch-12...\n"
     ]
    }
   ],
   "source": [
    "writer = create_writer(\"Run_3\", \"vit_small_patch14_reg4_dinov2\", \"lr-8.0e-05_epoch-100_batch-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatDataloader(Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch:int\n",
    "    ) -> None:\n",
    "        TRAIN_PERCENT = 00.4\n",
    "        self.dataset = dataset\n",
    "        self.batch = batch\n",
    "        self.dataset_size = len(dataset)\n",
    "        self.train_size = int(TRAIN_PERCENT * self.dataset_size)\n",
    "        self.test_size = int(0.01 * self.dataset_size)\n",
    "        # self.test_size = int((self.dataset_size - self.train_size)/2)\n",
    "        self.validation_size = self.dataset_size - self.train_size - self.test_size\n",
    "        self.train_data, self.test_data, self.validation_data = torch.utils.data.random_split(self.dataset,\n",
    "                                                                                              [self.train_size, self.test_size, self.validation_size])\n",
    "        \n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True)\n",
    "    \n",
    "    def get_test_dataloader(self):\n",
    "        return DataLoader(self.test_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True)\n",
    "        \n",
    "    def get_validation_dataloader(self):\n",
    "        return DataLoader(self.validation_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "dataloader = CreatDataloader(dataset, batch=12)\n",
    "training_dataloader = dataloader.get_train_dataloader()\n",
    "test_dataloader = dataloader.get_test_dataloader()\n",
    "validation_dataloader = dataloader.get_validation_dataloader()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "model = timm.create_model('vit_small_patch14_reg4_dinov2.lvd142m',\n",
    "                          pretrained=True,\n",
    "                          num_classes=0)\n",
    "\n",
    "model.head = nn.Sequential(nn.Linear(model.num_features, nbr_classes), nn.Sigmoid())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8.0e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        test_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        scheduler: torch.optim.lr_scheduler,\n",
    "        writer: SummaryWriter\n",
    "    ) -> None:\n",
    "        self.model = model.to(device)\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.epochs_run = 0\n",
    "        self.scheduler = scheduler\n",
    "        self.writer = writer\n",
    "        self.step = 0\n",
    "\n",
    "    def _run_batch(self, source, targets, idx):\n",
    "        NUM_ACCUMULATION_STEPS = 10\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = self.loss_fn(output, targets)\n",
    "        loss = loss / NUM_ACCUMULATION_STEPS\n",
    "        train_pred_labels = torch.round(output)\n",
    "        loss.backward()\n",
    "        if ((idx+1) % NUM_ACCUMULATION_STEPS == 0) or (idx+1 == len(self.train_data)):\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(\"Batch/Loss\", loss.item(), self.step)\n",
    "        self.step = self.step+1\n",
    "        return loss.item(), (torch.all(train_pred_labels == targets, dim=1).sum().item()/len(train_pred_labels))\n",
    "    # print(torch.all(y==sample[1].to(device), dim=1).sum().item()/len(y))\n",
    "        \n",
    "        \n",
    "    def _test_batch(self, source, targets):\n",
    "        test_output = self.model(source)\n",
    "        loss = self.loss_fn(test_output, targets)\n",
    "        test_pred_labels = torch.round(test_output)\n",
    "        return loss.item(), (torch.all(test_pred_labels == targets, dim=1).sum().item()/len(test_pred_labels))\n",
    "        \n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        test_loss, test_acc = 0, 0\n",
    "        train_loss, train_acc = 0, 0\n",
    "        b_sz = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{device}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n",
    "        for idx, sample in enumerate(self.train_data):\n",
    "            source = sample[0].to(device)\n",
    "            targets = sample[1].to(device)\n",
    "            loss, accu = self._run_batch(source, targets, idx)\n",
    "            train_loss += loss\n",
    "            train_acc += accu\n",
    "        self.scheduler.step()\n",
    "        train_loss = train_loss / len(self.train_data)\n",
    "        train_acc = train_acc / len(self.train_data)\n",
    "            \n",
    "        if epoch % 3 == 0:\n",
    "            self.model.eval()\n",
    "            with torch.inference_mode():\n",
    "                for source, targets in self.test_data:\n",
    "                    source = source.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    loss, accu = self._test_batch(source, targets)\n",
    "                    test_loss += loss\n",
    "                    test_acc += accu\n",
    "            test_loss = test_loss / len(self.test_data)\n",
    "            test_acc = test_acc / len(self.test_data)\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/test\", test_acc, epoch)\n",
    "            \n",
    "            \n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            self.writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(self.epochs_run, max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "        # Close the writer\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "Trainer = Trainer(model=model,\n",
    "                  train_data=training_dataloader,\n",
    "                  test_data=test_dataloader,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  scheduler=scheduler,\n",
    "                  writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPUcuda] Epoch 0 | Batchsize: 12 | Steps: 46935\n",
      "[GPUcuda] Epoch 1 | Batchsize: 12 | Steps: 46935\n",
      "[GPUcuda] Epoch 2 | Batchsize: 12 | Steps: 46935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m set_seed()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 86\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, max_epochs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_epochs: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs_run, max_epochs):\n\u001b[1;32m---> 86\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Close the writer\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m, in \u001b[0;36mTrainer._run_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     53\u001b[0m source \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     54\u001b[0m targets \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 55\u001b[0m loss, accu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     57\u001b[0m train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accu\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mTrainer._run_batch\u001b[1;34m(self, source, targets, idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter:\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBatch/Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem(), (torch\u001b[38;5;241m.\u001b[39mall(train_pred_labels \u001b[38;5;241m==\u001b[39m targets, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_pred_labels))\n",
      "File \u001b[1;32mc:\\Users\\joelc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:348\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metric_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    346\u001b[0m             w_hp\u001b[38;5;241m.\u001b[39madd_scalar(k, v)\n\u001b[1;32m--> 348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_scalar\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     tag,\n\u001b[0;32m    351\u001b[0m     scalar_value,\n\u001b[0;32m    352\u001b[0m     global_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     walltime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m     double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    356\u001b[0m ):\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add scalar data to summary.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "Trainer.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model, target_dir=\"models/final_models\", model_name=\"Dino_Run1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "output = model(ten_img)\n",
    "print(output[0].argmax())\n",
    "arg = int(output[0].argmax().cpu().detach().numpy())\n",
    "print(arg)\n",
    "print(spid_to_sp[cid_to_spid[arg]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_probabilities, top5_class_indices = torch.topk(output[0] * 100, k=5)\n",
    "top5_probabilities = top5_probabilities.cpu().detach().numpy()\n",
    "top5_class_indices = top5_class_indices.cpu().detach().numpy()\n",
    "\n",
    "print(top5_probabilities)\n",
    "\n",
    "for proba, cid in zip(top5_probabilities, top5_class_indices):\n",
    "    species_id = cid_to_spid[cid]\n",
    "    species = spid_to_sp[species_id]\n",
    "    print(species_id, species, proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
