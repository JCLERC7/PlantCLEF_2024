{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import timm.utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Function to set the seed for reproducibility\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "    # The below two lines are for deterministic algorithm behavior in CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/training/light_dataset\"\n",
    "nbr_classes = len(os.listdir(data_dir))\n",
    "nbr_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_mapping(class_list_file):\n",
    "    with open(class_list_file) as f:\n",
    "        class_index_to_class_name = {i: line.strip() for i, line in enumerate(f)}\n",
    "    return class_index_to_class_name\n",
    "\n",
    "\n",
    "def load_species_mapping(species_map_file):\n",
    "    df = pd.read_csv(species_map_file, sep=';', quoting=1, dtype={'species_id': str})\n",
    "    df = df.set_index('species_id')\n",
    "    return  df['species'].to_dict()\n",
    "\n",
    "cid_to_spid = load_class_mapping(\"models/pretrained_models/class_mapping.txt\")\n",
    "spid_to_sp = load_species_mapping(\"models/pretrained_models/species_id_to_name.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 518x518\n",
    "    transforms.Resize(size=(518,518)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # p = probability of flip, 0.5 = 50% chance\n",
    "    # Add your custom augmentation here\n",
    "    transforms.RandomApply([transforms.TrivialAugmentWide(num_magnitude_bins=31)], p=0.5),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize the image\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def one_hot(label_idx, nbr_classes):\n",
    "    one_hot_tensor = torch.zeros(nbr_classes)\n",
    "    one_hot_tensor.scatter_(0, torch.tensor(label_idx), value=1)\n",
    "    return one_hot_tensor\n",
    "\n",
    "label_transformation = transforms.Compose([transforms.Lambda(lambda y: one_hot(y, nbr_classes))])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir,\n",
    "                            transform=data_transform,\n",
    "                            target_transform= label_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor:\n",
      "tensor([[[-0.6794, -0.6623, -0.6623,  ..., -0.4397, -0.6109, -0.8164],\n",
      "         [-0.6281, -0.6281, -0.6109,  ..., -1.0390, -1.2445, -1.2617],\n",
      "         [-0.7650, -0.6965, -0.6109,  ..., -1.3815, -1.4158, -1.2959],\n",
      "         ...,\n",
      "         [-0.6281, -0.4911, -0.3883,  ..., -0.6281, -0.6452, -0.6281],\n",
      "         [-0.5082, -0.6794, -0.9192,  ..., -0.6623, -0.6623, -0.6452],\n",
      "         [-1.5014, -1.4843, -1.4843,  ..., -0.6281, -0.6281, -0.6281]],\n",
      "\n",
      "        [[ 0.8179,  0.8354,  0.8354,  ...,  0.7479,  0.6954,  0.5378],\n",
      "         [ 0.7654,  0.7829,  0.8004,  ...,  0.1001, -0.0049,  0.0301],\n",
      "         [ 0.4678,  0.5378,  0.6254,  ..., -0.3375, -0.2675, -0.0924],\n",
      "         ...,\n",
      "         [ 0.6429,  0.7654,  0.8529,  ...,  0.7654,  0.7479,  0.7654],\n",
      "         [ 0.5203,  0.3452,  0.0826,  ...,  0.7304,  0.7304,  0.7304],\n",
      "         [-0.7052, -0.7052, -0.7402,  ...,  0.7479,  0.7479,  0.7479]],\n",
      "\n",
      "        [[-0.4973, -0.4798, -0.4798,  ..., -0.3404, -0.5321, -0.7413],\n",
      "         [-0.4275, -0.4275, -0.4101,  ..., -0.9853, -1.2293, -1.2641],\n",
      "         [-0.5670, -0.4973, -0.4450,  ..., -1.4210, -1.4733, -1.3513],\n",
      "         ...,\n",
      "         [-1.1247, -0.9678, -0.8284,  ...,  0.1999,  0.1999,  0.2173],\n",
      "         [-0.9156, -1.0201, -1.2119,  ...,  0.2173,  0.2348,  0.2696],\n",
      "         [-1.6127, -1.6476, -1.6650,  ...,  0.2871,  0.2871,  0.3045]]])\n",
      "Image shape: torch.Size([3, 518, 518])\n",
      "Image datatype: torch.float32\n",
      "Image label: tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Label datatype: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[0][0], dataset[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer( experiment_name: str, model_name: str, extra: str=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "    \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs\\2024-05-31\\Run_3\\vit_small_patch14_reg4_dinov2\\lr-8.0e-05_epoch-100_batch-24_light_dataset...\n"
     ]
    }
   ],
   "source": [
    "writer = create_writer(\"Run_3\", \"vit_small_patch14_reg4_dinov2\", \"lr-8.0e-05_epoch-100_batch-24_light_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatDataloader(Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch:int\n",
    "    ) -> None:\n",
    "        TRAIN_PERCENT = 0.8\n",
    "        self.dataset = dataset\n",
    "        self.batch = batch\n",
    "        self.dataset_size = len(dataset)\n",
    "        self.train_size = int(TRAIN_PERCENT * self.dataset_size)\n",
    "        # self.test_size = int(0.01 * self.dataset_size)\n",
    "        self.test_size = int((self.dataset_size - self.train_size)/2)\n",
    "        self.validation_size = self.dataset_size - self.train_size - self.test_size\n",
    "        self.train_data, self.test_data, self.validation_data = torch.utils.data.random_split(self.dataset,\n",
    "                                                                                              [self.train_size, self.test_size, self.validation_size])\n",
    "        \n",
    "    def get_train_dataloader(self):\n",
    "        return DataLoader(self.train_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True)\n",
    "    \n",
    "    def get_test_dataloader(self):\n",
    "        return DataLoader(self.test_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True)\n",
    "        \n",
    "    def get_validation_dataloader(self):\n",
    "        return DataLoader(self.validation_data,\n",
    "                          batch_size=self.batch,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "dataloader = CreatDataloader(dataset, batch=24)\n",
    "training_dataloader = dataloader.get_train_dataloader()\n",
    "test_dataloader = dataloader.get_test_dataloader()\n",
    "validation_dataloader = dataloader.get_validation_dataloader()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "model = timm.create_model('vit_small_patch14_reg4_dinov2.lvd142m',\n",
    "                          pretrained=True,\n",
    "                          num_classes=0)\n",
    "\n",
    "model.head = nn.Sequential(nn.Linear(model.num_features, nbr_classes), nn.Sigmoid())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8.0e-05)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_data: DataLoader,\n",
    "        test_data: DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        scheduler: torch.optim.lr_scheduler,\n",
    "        writer: SummaryWriter\n",
    "    ) -> None:\n",
    "        self.model = model.to(device)\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.epochs_run = 0\n",
    "        self.scheduler = scheduler\n",
    "        self.writer = writer\n",
    "        self.step = 0\n",
    "\n",
    "    def _run_batch(self, source, targets, idx):\n",
    "        NUM_ACCUMULATION_STEPS = 10\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(source)\n",
    "        loss = self.loss_fn(output, targets)\n",
    "        loss = loss / NUM_ACCUMULATION_STEPS\n",
    "        train_pred_labels = torch.round(output)\n",
    "        loss.backward()\n",
    "        if ((idx+1) % NUM_ACCUMULATION_STEPS == 0) or (idx+1 == len(self.train_data)):\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(\"Batch/Loss\", loss.item(), self.step)\n",
    "        self.step = self.step+1\n",
    "        return loss.item(), ((train_pred_labels == targets).sum().item()/torch.numel(train_pred_labels))\n",
    "    # print(torch.all(y==sample[1].to(device), dim=1).sum().item()/len(y))\n",
    "        \n",
    "        \n",
    "    def _test_batch(self, source, targets):\n",
    "        test_output = self.model(source)\n",
    "        loss = self.loss_fn(test_output, targets)\n",
    "        test_pred_labels = torch.round(test_output)\n",
    "        return loss.item(), ((test_pred_labels == targets).sum().item()/torch.numel(test_pred_labels))\n",
    "        \n",
    "\n",
    "    def _run_epoch(self, epoch):\n",
    "        test_loss, test_acc = 0, 0\n",
    "        train_loss, train_acc = 0, 0\n",
    "        b_sz = len(next(iter(self.train_data))[0])\n",
    "        print(f\"[GPU{device}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)} | Time: {datetime.now()}\")\n",
    "        for idx, sample in enumerate(self.train_data):\n",
    "            source = sample[0].to(device)\n",
    "            targets = sample[1].to(device)\n",
    "            loss, accu = self._run_batch(source, targets, idx)\n",
    "            train_loss += loss\n",
    "            train_acc += accu\n",
    "        self.scheduler.step()\n",
    "        train_loss = train_loss / len(self.train_data)\n",
    "        train_acc = train_acc / len(self.train_data)\n",
    "            \n",
    "        if epoch % 3 == 0:\n",
    "            self.model.eval()\n",
    "            with torch.inference_mode():\n",
    "                for source, targets in self.test_data:\n",
    "                    source = source.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    loss, accu = self._test_batch(source, targets)\n",
    "                    test_loss += loss\n",
    "                    test_acc += accu\n",
    "            test_loss = test_loss / len(self.test_data)\n",
    "            test_acc = test_acc / len(self.test_data)\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "                self.writer.add_scalar(\"Accuracy/test\", test_acc, epoch)\n",
    "            \n",
    "            \n",
    "        if self.writer:\n",
    "            self.writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "            self.writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def train(self, max_epochs: int):\n",
    "        for epoch in range(self.epochs_run, max_epochs):\n",
    "            self._run_epoch(epoch)\n",
    "        # Close the writer\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "Trainer = Trainer(model=model,\n",
    "                  train_data=training_dataloader,\n",
    "                  test_data=test_dataloader,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  scheduler=scheduler,\n",
    "                  writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPUcuda] Epoch 0 | Batchsize: 24 | Steps: 6680 | Time: 2024-05-31 01:06:13.562040\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "Trainer.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "      either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model, target_dir=\"models/final_models\", model_name=\"Dino_Run1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# output = model(ten_img)\n",
    "# print(output[0].argmax())\n",
    "# arg = int(output[0].argmax().cpu().detach().numpy())\n",
    "# print(arg)\n",
    "# print(spid_to_sp[cid_to_spid[arg]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top5_probabilities, top5_class_indices = torch.topk(output[0] * 100, k=5)\n",
    "# top5_probabilities = top5_probabilities.cpu().detach().numpy()\n",
    "# top5_class_indices = top5_class_indices.cpu().detach().numpy()\n",
    "\n",
    "# print(top5_probabilities)\n",
    "\n",
    "# for proba, cid in zip(top5_probabilities, top5_class_indices):\n",
    "#     species_id = cid_to_spid[cid]\n",
    "#     species = spid_to_sp[species_id]\n",
    "#     print(species_id, species, proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
